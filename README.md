 Object Detection System for Blind Persons using MobileNet SSD
An AI-powered assistive system designed to help visually impaired individuals by detecting and identifying objects in real-time, providing audio feedback for enhanced environmental awareness.

âœ¨ Key Features:
ğŸ–¼ï¸ Real-time Object Detection: Utilizes the MobileNet SSD deep learning model for fast and accurate object recognition.
ğŸ¤ Audio Feedback: Converts detected objects into speech output to inform users.
ğŸ“· Live Video Processing: Captures and processes webcam feed continuously.
ğŸ”„ User-Friendly & Efficient: Lightweight design for potential deployment on portable devices.
ğŸ“¦ Pretrained Model Usage: Uses MobileNet SSD pretrained weights for reliable detection.

ğŸ› ï¸ Tech Stack:
Deep Learning Model: MobileNet SSD
Languages: Python
Libraries: OpenCV, NumPy, TensorFlow/PyTorch
Audio: pyttsx3 / gTTS for speech synthesis

Hardware: Webcam or camera device

ğŸ”‘ API Keys
This project integrates with external services using two API keys:
OpenWeather API: To fetch real-time weather updates and environmental conditions.
OpenRoute API: To provide navigation assistance and routing information.
Note: You need to obtain your own API keys from OpenWeather and OpenRoute and add them to the project configuration before running.


ğŸ“‹ How to Run
Clone the repository:
git clone https://github.com/vinothinik05/object-detection-for-blind-person-using-dl-MoblieNetSSD-model-.git

Install required libraries:
pip install -r requirements.txt

Run the detection script:
python detect.py

Ensure your webcam is connected and active. The system will start detecting objects and provide audio feedback in real-time.

ğŸ“ Repository Structure:
/object-detection-for-blind-person-using-dl-MoblieNetSSD-model-
â”‚
â”œâ”€â”€ detect.py             # Main script to run object detection
â”œâ”€â”€ MobileNetSSD_deploy.prototxt  # Model configuration
â”œâ”€â”€ MobileNetSSD_deploy.caffemodel # Pretrained weights
â”œâ”€â”€ requirements.txt      # Python dependencies
â””â”€â”€ README.md             # Project documentation


ğŸ¯ Future Improvements
Add positional audio cues (e.g., left/right object location).
optimize model for mobile and embedded systems.
Incorporate voice command controls.
Enhance detection accuracy with fine-tuned/custom models.

ğŸ“§ Contact:
For questions or collaboration:
ğŸ“§ vino12752@gmail.com
